{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnLf_0DXSBJl",
    "outputId": "1bc7234a-7e27-4d83-b664-afad5e5ebd39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Using cached scikeras-0.12.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: packaging>=0.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikeras) (23.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikeras) (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.0->scikeras) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
      "Using cached scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.12.0\n",
      "Collecting shap\n",
      "  Downloading shap-0.45.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from shap) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from shap) (1.4.1.post1)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from shap) (2.0.1)\n",
      "Collecting tqdm>=4.27.0 (from shap)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m385.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>20.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from shap) (23.1)\n",
      "Collecting slicer==0.0.7 (from shap)\n",
      "  Using cached slicer-0.0.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting numba (from shap)\n",
      "  Downloading numba-0.59.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting cloudpickle (from shap)\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba->shap)\n",
      "  Downloading llvmlite-0.42.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->shap) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->shap) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Downloading shap-0.45.0-cp311-cp311-macosx_10_9_x86_64.whl (457 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.1/457.1 kB\u001b[0m \u001b[31m547.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m831.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading numba-0.59.1-cp311-cp311-macosx_10_9_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading llvmlite-0.42.0-cp311-cp311-macosx_10_9_x86_64.whl (31.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.1/31.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, slicer, llvmlite, cloudpickle, numba, shap\n",
      "Successfully installed cloudpickle-3.0.0 llvmlite-0.42.0 numba-0.59.1 shap-0.45.0 slicer-0.0.7 tqdm-4.66.2\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras\n",
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXTE6z76PB4e"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, precision_score, f1_score, accuracy_score, roc_auc_score, roc_curve, auc, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZrFWXpWPT4f"
   },
   "outputs": [],
   "source": [
    "# import the training data\n",
    "# data does not persist after runtime\n",
    "# everytime the notebook is run we need to re-upload the data\n",
    "data_raw = pd.read_excel('/content/data.xlsx', index_col=0)\n",
    "\n",
    "# set up lags for looping\n",
    "lags = [3, 6, 9, 12, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PgcfwlC36sMF"
   },
   "outputs": [],
   "source": [
    "# helper function to flatten list of nested lists\n",
    "# the predicted values are returned like this:\n",
    "# i.e. [[0],[1],[0],[1]]\n",
    "# we need to convert it to this:\n",
    "# i.e. [0,1,0,1]\n",
    "def flatten_list(matrix_list):\n",
    "    flat_list = []\n",
    "    for row in matrix_list:\n",
    "        flat_list.append(row[0])\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzhyIyGx1lwM"
   },
   "outputs": [],
   "source": [
    "# set up function to loop over and test different\n",
    "# thresholds then extract the best one\n",
    "def find_best_threshold(y_predicted_raw, y_true, flatten_function):\n",
    "    # create range from 0.4-0.9\n",
    "    # we can only use range with full integers\n",
    "    # first step is to make list 40-90 in increments of 5\n",
    "    # then divide each by 100\n",
    "    threshold_intervals = [(i / 100) for i in range(40, 91, 5)]\n",
    "    # now loop over each interval and run the model\n",
    "    # to see which one performs best\n",
    "    # create list to store the results\n",
    "    results = []\n",
    "    for threshold in threshold_intervals:\n",
    "        # compare at each threshold\n",
    "        y_pred_at_threshold = [(1 if pred > threshold else 0) for pred in y_predicted_raw]\n",
    "        # flatten the results\n",
    "        #y_pred_at_threshold = flatten_function(y_pred_at_threshold)\n",
    "        # calcuate the f1 score for the predicted\n",
    "        threshold_f1 = f1_score(y_true, y_pred_at_threshold)\n",
    "        # create tuple of each threshold and f1\n",
    "        results.append((threshold_f1, y_pred_at_threshold, threshold))\n",
    "    # find the threshold with the max f1\n",
    "    max_threshold_tuple = max(results, key=lambda x: x[0])\n",
    "    # now extract the threshold from tuple\n",
    "    best_threshold = max_threshold_tuple[2]\n",
    "    y_pred = max_threshold_tuple[1]\n",
    "    best_f1 = max_threshold_tuple[0]\n",
    "    # return the result\n",
    "    return [best_threshold, y_pred, best_f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1F-ZBf6FYkEv"
   },
   "outputs": [],
   "source": [
    "# create the dirs to export the plots\n",
    "# then assign the paths to export the direct\n",
    "# to export the plots\n",
    "plots_dirs = ['nn-roc-plots', 'nn-shap-plots']\n",
    "# loop and create\n",
    "for dir in plots_dirs:\n",
    "  folder_path = os.path.join('/content/', dir)\n",
    "  os.makedirs(folder_path, exist_ok=True)\n",
    "# set up dir paths to export the model plots\n",
    "# roc curve plots\n",
    "roc_fig_dir_path = '/content/nn-roc-plots/'\n",
    "# shap plots\n",
    "shap_fig_dir_path = '/content/nn-shap-plots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJWG1muMAxZa"
   },
   "outputs": [],
   "source": [
    "# helper function to properly format the input data\n",
    "# for the shap package since the format\n",
    "# is a nested list of lists\n",
    "def flatten_shap_vals(shap_values):\n",
    "  # initialize result\n",
    "  result = []\n",
    "  # loop and flatten\n",
    "  for values in shap_values:\n",
    "    # convert single item inner arrays to one list\n",
    "    flattened_list = [element[0] for element in values]\n",
    "    # append result\n",
    "    result.append(flattened_list)\n",
    "  # convert to np array\n",
    "  result = np.array(result)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrfuG1cLX20K"
   },
   "outputs": [],
   "source": [
    "# helper function to perform shap analysis\n",
    "# used these tutorials\n",
    "# https://shorturl.at/nwGP8\n",
    "# don't need to pass in training data for tree models\n",
    "def shap_analysis(model, X_test, X_train, fig_dir_path, model_name, lag):\n",
    "    # get the shap explainer variables\n",
    "    #explainer = shap.DeepExplainer(model, data=X_train)\n",
    "    explainer = shap.KernelExplainer(model.predict, X_train)\n",
    "    # get the raw shap values\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    print('SHAP_VALUES: ', shap_values)\n",
    "    print('SHAP VALUES SHAPE: ', shap_values.shape)\n",
    "    # we need to extract the correct values\n",
    "    # this is a quirk of the nn models' outputs\n",
    "    # i.e. SHAP VALUES SHAPE:  (1, 6, 1)\n",
    "    # i.e. SHAP_VALUES:  [[[-1.92598999e-03], ..., [ 6.42130772e-04]]]\n",
    "    # we need the innermost arrays to be one list\n",
    "    flat_shap = flatten_shap_vals(shap_values)\n",
    "    print('FLATTENED SHAP: ', flat_shap)\n",
    "    print('FLAT SHAP SHAPE: ', flat_shap.shape)\n",
    "    # create explainer object\n",
    "    shap_expl = shap.Explanation(flat_shap, base_values=explainer.expected_value, data=X_test)\n",
    "    # create file name\n",
    "    file_name = f\"beeswarm_plt_{model_name}_lag_{lag}.png\"\n",
    "    # initialize save path\n",
    "    save_path = os.path.join(fig_dir_path, file_name)\n",
    "    # create figure object and set size\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # create beeswarm plot\n",
    "    shap.plots.beeswarm(shap_expl, show=False)\n",
    "    plt.tight_layout()\n",
    "    # save the plot\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    # create file name for summary plot\n",
    "    summary_file_name = f\"summary_plot_{model_name}_lag_{lag}.png\"\n",
    "    summary_save_path = os.path.join(fig_dir_path, summary_file_name)\n",
    "    # create figure for the summary plot as well\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # create summary plot\n",
    "    shap.summary_plot(flat_shap, X_test, plot_type='bar', show=False)\n",
    "    plt.tight_layout()\n",
    "    # export plot\n",
    "    plt.savefig(summary_save_path, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-556LVhWZ3Sq"
   },
   "outputs": [],
   "source": [
    "# helper function to create roc_curve\n",
    "def roc_curve_plot(y_true, y_pred_prob, lag, fig_dir_path, model_name):\n",
    "    # get the fpr, trp, and thresholds\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "    # call method on fpr and tpr\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # create plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # we insert the area under curve up to 2 decimal places\n",
    "    # we can insert using the modulo operator - %\n",
    "    plt.plot(fpr, tpr, color='lightblue', linewidth=2, label='ROC Curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='darkred', linewidth=2, linestyle=':')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f\"Logit ROC Curve for {lag} Month Lag\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    file_name = f\"roc_curve_{model_name}_lag_{lag}.png\"\n",
    "    save_path = os.path.join(fig_dir_path, file_name)\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAtwwBS6dP1q"
   },
   "outputs": [],
   "source": [
    "# create parameter grid to pass in\n",
    "# this will help us extract the best model when we do the grid search\n",
    "param_grid = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [10, 20, 30],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'loss': ['binary_crossentropy', 'hinge']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBJNrCYgrLU-"
   },
   "outputs": [],
   "source": [
    "# helper function to start create a new nn model\n",
    "# creates a neural network with two hidden layers\n",
    "# we pass this in as the build function\n",
    "def create_model(input_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCudK7C6bW0h"
   },
   "source": [
    "def neural_network_grid_search(data, lag, test_size, scoring, param_grid):\n",
    "    \"\"\"\n",
    "    Function to run neural network with grid search for hyperparameters\n",
    "    \"\"\"\n",
    "\n",
    "    # make a copy of the original DataFrame to avoid modifying it\n",
    "    data_copy = data.copy()\n",
    "\n",
    "    # modify dataset for lag\n",
    "    data_copy[f\"nber_recession_{lag}_month_lag\"] = data_copy['nber_recession'].shift(-lag)\n",
    "\n",
    "    # drop the original recession column and na values\n",
    "    data_copy = data_copy.drop(columns=['nber_recession'])\n",
    "    data_copy = data_copy.dropna()\n",
    "\n",
    "    # set up training and testing data\n",
    "    X = data_copy.drop(columns=[f\"nber_recession_{lag}_month_lag\"])\n",
    "    y = data_copy[f\"nber_recession_{lag}_month_lag\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "    # apply SMOTE only to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # compile the initial model\n",
    "    # pass in the starting optimizer and loss functions\n",
    "    # in order to perform grid search, we need to pass in the model here\n",
    "    # this tells keras that we are passing in a model that should be\n",
    "    # used for classification, otherwise, grid search with a neural network\n",
    "    # becomes very complicated\n",
    "    model = KerasClassifier(build_fn=create_model, input_dim=X_train_resampled.shape[1], verbose=1)\n",
    "\n",
    "    # perform grid search\n",
    "    grid_search_cv = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=scoring, verbose=1)\n",
    "    grid_result = grid_search_cv.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # get best model from the grid search\n",
    "    best_model = grid_result.best_estimator_\n",
    "    # also extract the parameters\n",
    "    best_parameters = grid_result.best_params_\n",
    "\n",
    "    # get the predicted values\n",
    "    # returns list of list\n",
    "    # [chance 0, chance 1]\n",
    "    y_pred_raw = best_model.predict_proba(X_test)\n",
    "\n",
    "    # extract the chance of positive classification\n",
    "    # since the predict_proba returns list of lists\n",
    "    # of the chance 0 and 1 classification\n",
    "    # this behaves a bit differently than the other models\n",
    "    # so we need to use a list comp to extract the\n",
    "    # positive chances unlike with other models where we\n",
    "    # can extract like [:,1]\n",
    "    y_pred_prob_positive = [pred[1] for pred in y_pred_raw]\n",
    "\n",
    "    # extract the data for the best threshold\n",
    "    best_model_results = find_best_threshold(y_pred_prob_positive, y_test, flatten_list)\n",
    "    # extract the relevant results\n",
    "    threshold = best_model_results[0]\n",
    "    y_pred = best_model_results[1]\n",
    "    best_f1 = best_model_results[2]\n",
    "\n",
    "    # create a confusion matrix to visualize results\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # make the roc_curve plot\n",
    "    # this does not take into account\n",
    "    # the threshold we ind. calculate\n",
    "    roc_curve_plot(y_test, y_pred_prob_positive, lag, roc_fig_dir_path, 'nn')\n",
    "\n",
    "    # perform shap analyis on the model\n",
    "    # we need to unwrap the keras model since KerasKlassifier is not\n",
    "    # yet supported by the shap package\n",
    "    # error: <class 'scikeras.wrappers.KerasClassifier'> is not currently a supported model type!\n",
    "    # unwrapped model\n",
    "    # reference: https://shorturl.at/rIKY1\n",
    "    unwrapped_model = best_model.model_\n",
    "    print('UNWRAPPED MODEL: ', unwrapped_model)\n",
    "    print('BEST MODEL: ', best_model)\n",
    "    shap_analysis(unwrapped_model, X_test, X_train_resampled, shap_fig_dir_path, 'nn', lag)\n",
    "\n",
    "    # get predicted values and metrics\n",
    "    metrics_obj= {\n",
    "       'accuracy': accuracy_score(y_test, y_pred),\n",
    "       'precision': precision_score(y_test, y_pred),\n",
    "       'recall': recall_score(y_test, y_pred),\n",
    "       'f1': best_f1,\n",
    "       'roc_auc': roc_auc_score(y_test, y_pred_prob_positive),\n",
    "       }\n",
    "\n",
    "    return {'data': data_copy,\n",
    "            'best_model': best_model,\n",
    "            'best_parameters': best_parameters,\n",
    "            'best_threshold': threshold,\n",
    "            'y_true': y_test,\n",
    "            'predicted_vals_binary': y_pred,\n",
    "            'confusion_matrix': conf_mat,\n",
    "            'model_metrics': metrics_obj}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q-Qt9_icRBj7",
    "outputId": "fe203f21-33f8-4ad9-abdf-a55c788acf3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Epoch 1/10\n",
      "52/52 [==============================] - 1s 3ms/step - loss: 0.7222 - accuracy: 0.4808\n",
      "Epoch 2/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.5072\n",
      "Epoch 3/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.5180\n",
      "Epoch 4/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.5974\n",
      "Epoch 5/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.6346\n",
      "Epoch 6/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.6947\n",
      "Epoch 7/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.7139\n",
      "Epoch 8/10\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6077 - accuracy: 0.7272\n",
      "Epoch 9/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.7452\n",
      "Epoch 10/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7644\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "52/52 [==============================] - 2s 22ms/step - loss: 0.7068 - accuracy: 0.4844\n",
      "Epoch 2/10\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6726 - accuracy: 0.5805\n",
      "Epoch 3/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.6166\n",
      "Epoch 4/10\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.7163\n",
      "Epoch 5/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6947\n",
      "Epoch 6/10\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.5855 - accuracy: 0.7596\n",
      "Epoch 7/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.7632\n",
      "Epoch 8/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7716\n",
      "Epoch 9/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7788\n",
      "Epoch 10/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7837\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "52/52 [==============================] - 4s 32ms/step - loss: 0.7130 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.5505\n",
      "Epoch 3/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.6538\n",
      "Epoch 4/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.6875\n",
      "Epoch 5/10\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.7007\n",
      "Epoch 6/10\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.5953 - accuracy: 0.7332\n",
      "Epoch 7/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7428\n",
      "Epoch 8/10\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7644\n",
      "Epoch 9/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7620\n",
      "Epoch 10/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7716\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "52/52 [==============================] - 3s 19ms/step - loss: 0.7093 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6519 - accuracy: 0.5865\n",
      "Epoch 3/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6659\n",
      "Epoch 4/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.7212\n",
      "Epoch 5/10\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5921 - accuracy: 0.7356\n",
      "Epoch 6/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7488\n",
      "Epoch 7/10\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5445 - accuracy: 0.7656\n",
      "Epoch 8/10\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.5159 - accuracy: 0.7776\n",
      "Epoch 9/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7776\n",
      "Epoch 10/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7849\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "52/52 [==============================] - 3s 37ms/step - loss: 0.7232 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.6793 - accuracy: 0.5084\n",
      "Epoch 3/10\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6628 - accuracy: 0.6010\n",
      "Epoch 4/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.6971\n",
      "Epoch 5/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6995\n",
      "Epoch 6/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7320\n",
      "Epoch 7/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7368\n",
      "Epoch 8/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7632\n",
      "Epoch 9/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7608\n",
      "Epoch 10/10\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5102 - accuracy: 0.7704\n",
      "13/13 [==============================] - 0s 16ms/step\n",
      "Epoch 1/10\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.7168 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6814 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.5613\n",
      "Epoch 4/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.6046\n",
      "Epoch 5/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.6887\n",
      "Epoch 6/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7067\n",
      "Epoch 7/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.7236\n",
      "Epoch 8/10\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.5992 - accuracy: 0.7392\n",
      "Epoch 9/10\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5755 - accuracy: 0.7632\n",
      "Epoch 10/10\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.5558 - accuracy: 0.7692\n",
      "13/13 [==============================] - 0s 15ms/step\n",
      "Epoch 1/10\n",
      "52/52 [==============================] - 2s 3ms/step - loss: 0.7203 - accuracy: 0.4062\n",
      "Epoch 2/10\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.5312\n",
      "Epoch 3/10\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.6559 - accuracy: 0.6647\n",
      "Epoch 4/10\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.6475 - accuracy: 0.6935\n",
      "Epoch 5/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.7260\n",
      "Epoch 6/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.7380\n",
      "Epoch 7/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.7644\n",
      "Epoch 8/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7800\n",
      "Epoch 9/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7861\n",
      "Epoch 10/10\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5127 - accuracy: 0.7812\n",
      "13/13 [==============================] - 1s 69ms/step\n",
      "Epoch 1/10\n",
      "52/52 [==============================] - 1s 2ms/step - loss: 0.7153 - accuracy: 0.3017\n",
      "Epoch 2/10\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6887 - accuracy: 0.5312\n",
      "Epoch 3/10\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.6142\n",
      "Epoch 4/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6659 - accuracy: 0.6599\n",
      "Epoch 5/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6995\n",
      "Epoch 6/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.7200\n",
      "Epoch 7/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.7368\n",
      "Epoch 8/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7524\n",
      "Epoch 9/10\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5439 - accuracy: 0.7620\n",
      "Epoch 10/10\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7680\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "52/52 [==============================] - 2s 23ms/step - loss: 0.7155 - accuracy: 0.4651\n",
      "Epoch 2/10\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.6713 - accuracy: 0.5733\n",
      "Epoch 3/10\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.6623\n",
      "Epoch 4/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.7344\n",
      "Epoch 5/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.7320\n",
      "Epoch 6/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7560\n",
      "Epoch 7/10\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.5477 - accuracy: 0.7668\n",
      "Epoch 8/10\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5255 - accuracy: 0.7728\n",
      "Epoch 9/10\n",
      "52/52 [==============================] - 1s 8ms/step - loss: 0.5079 - accuracy: 0.7752\n",
      "Epoch 10/10\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7812\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "52/52 [==============================] - 1s 3ms/step - loss: 0.7275 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.6743 - accuracy: 0.5168\n",
      "Epoch 3/10\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.6650 - accuracy: 0.6070\n",
      "Epoch 4/10\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.6469 - accuracy: 0.6779\n",
      "Epoch 5/10\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6303 - accuracy: 0.7139\n",
      "Epoch 6/10\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6053 - accuracy: 0.7296\n",
      "Epoch 7/10\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5815 - accuracy: 0.7356\n",
      "Epoch 8/10\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.5581 - accuracy: 0.7500\n",
      "Epoch 9/10\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.5369 - accuracy: 0.7656\n",
      "Epoch 10/10\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.7728\n",
      "13/13 [==============================] - 1s 47ms/step\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 4s 34ms/step - loss: 0.7332 - accuracy: 0.3762\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.5120\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.5325\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6034\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6394\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 3s 59ms/step - loss: 0.6373 - accuracy: 0.7007\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 3s 56ms/step - loss: 0.6297 - accuracy: 0.7163\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.6037 - accuracy: 0.7416\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.5902 - accuracy: 0.7464\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7740\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7764\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7812\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7812\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5048 - accuracy: 0.7837\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4968 - accuracy: 0.7849\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.4882 - accuracy: 0.7861\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7873\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7909\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7933\n",
      "13/13 [==============================] - 1s 72ms/step\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 4s 21ms/step - loss: 0.7109 - accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6628 - accuracy: 0.6082\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.6643 - accuracy: 0.6454\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6248 - accuracy: 0.7175\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5993 - accuracy: 0.7380\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.5741 - accuracy: 0.7620\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 2s 26ms/step - loss: 0.5504 - accuracy: 0.7800\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7800\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5115 - accuracy: 0.7837\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5005 - accuracy: 0.7849\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7909\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7897\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.4723 - accuracy: 0.7885\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7897\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7909\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7945\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7957\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 3s 58ms/step - loss: 0.4498 - accuracy: 0.7981\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.4466 - accuracy: 0.7981\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 0.4434 - accuracy: 0.7981\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 3s 27ms/step - loss: 0.7161 - accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.6680 - accuracy: 0.5240\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.6674 - accuracy: 0.5974\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6523 - accuracy: 0.6490\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.6983\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.7139\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.7308\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.5700 - accuracy: 0.7488\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7728\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7716\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7752\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7776\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7825\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7825\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4754 - accuracy: 0.7849\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7861\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7897\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7933\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7957\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7969\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 1s 3ms/step - loss: 0.7109 - accuracy: 0.4243\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.5865\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.6286\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.6458 - accuracy: 0.7103\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.6308 - accuracy: 0.7163\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.7344\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7584\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7692\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7740\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7776\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4862 - accuracy: 0.7837\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7897\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7933\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7969\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.8005\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.8005\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.8041\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.8053\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8077\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.8089\n",
      "13/13 [==============================] - 1s 70ms/step\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 2s 3ms/step - loss: 0.7189 - accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.6725 - accuracy: 0.5325\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.6568 - accuracy: 0.6454\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6803\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.7115\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.7284\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7428\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7584\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7680\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7692\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7716\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7812\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.4828 - accuracy: 0.7825\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.4770 - accuracy: 0.7837\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7849\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7861\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7921\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7945\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.4539 - accuracy: 0.7969\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8005\n",
      "13/13 [==============================] - 1s 61ms/step\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 3s 36ms/step - loss: 0.7285 - accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.6800 - accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.5312\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.6058\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6522 - accuracy: 0.6623\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.6384 - accuracy: 0.6983\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6172 - accuracy: 0.7236\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.7368\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.7572\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5691 - accuracy: 0.7608\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 0.5514 - accuracy: 0.7716\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.5350 - accuracy: 0.7776\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7812\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7825\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7812\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7837\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7873\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.4808 - accuracy: 0.7873\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4745 - accuracy: 0.7873\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7885\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 2s 19ms/step - loss: 0.7154 - accuracy: 0.3918\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.6719 - accuracy: 0.6034\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.6310\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7188\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.7139\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7596\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7512\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5344 - accuracy: 0.7776\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5154 - accuracy: 0.7800\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5012 - accuracy: 0.7837\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7873\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7909\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7921\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7945\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7945\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.4588 - accuracy: 0.7969\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4548 - accuracy: 0.8017\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8017\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.8065\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.8077\n",
      "13/13 [==============================] - 0s 24ms/step\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 2s 19ms/step - loss: 0.7176 - accuracy: 0.4675\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6806 - accuracy: 0.5024\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6746 - accuracy: 0.5529\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.6358\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6911\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.7139\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.7284\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.7440\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.5531 - accuracy: 0.7752\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.5329 - accuracy: 0.7740\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7752\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7788\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.7812\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7825\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7849\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7849\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.4637 - accuracy: 0.7885\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4615 - accuracy: 0.7909\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7921\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7957\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 1s 3ms/step - loss: 0.7003 - accuracy: 0.5036\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.5673\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.6572 - accuracy: 0.6587\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.6433 - accuracy: 0.7019\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6172 - accuracy: 0.7332\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.7344\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.7560\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7644\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7704\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.5019 - accuracy: 0.7776\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7812\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7873\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7909\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7921\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7969\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.4489 - accuracy: 0.7969\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4435 - accuracy: 0.8029\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.8017\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.8041\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8065\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 3s 21ms/step - loss: 0.7303 - accuracy: 0.4940\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 0.6789 - accuracy: 0.5048\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6691 - accuracy: 0.5817\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.6430\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.6947\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.6213 - accuracy: 0.7212\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.7308\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7404\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7632\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7680\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5219 - accuracy: 0.7752\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5079 - accuracy: 0.7752\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7788\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7837\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7897\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7921\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7909\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4607 - accuracy: 0.7945\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4562 - accuracy: 0.7957\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7957\n",
      "13/13 [==============================] - 1s 38ms/step\n",
      "Epoch 1/30\n",
      "52/52 [==============================] - 2s 21ms/step - loss: 0.7186 - accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6854 - accuracy: 0.5060\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.5841\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.6046\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6983\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.6995\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.7368\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.7488\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7644\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.7644\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7716\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7764\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5082 - accuracy: 0.7752\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7812\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7825\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7849\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4779 - accuracy: 0.7849\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7861\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7885\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7909\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.4596 - accuracy: 0.7945\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.4559 - accuracy: 0.7957\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4524 - accuracy: 0.7981\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7993\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7993\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.8041\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7981\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.4359 - accuracy: 0.8065\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.8053\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8101\n",
      "13/13 [==============================] - 1s 39ms/step\n",
      "Epoch 1/30\n",
      "52/52 [==============================] - 3s 36ms/step - loss: 0.6968 - accuracy: 0.4796\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6825 - accuracy: 0.6190\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.6599\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.6094\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.7464\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7524\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7584\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5375 - accuracy: 0.7716\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.5189 - accuracy: 0.7764\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7776\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7849\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7861\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7909\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7921\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4653 - accuracy: 0.7909\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.4608 - accuracy: 0.7945\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7957\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7957\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7957\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.4465 - accuracy: 0.7993\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4439 - accuracy: 0.7993\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7993\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8017\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8029\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.8029\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8041\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.4295 - accuracy: 0.8065\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4279 - accuracy: 0.8077\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8101\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8089\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "52/52 [==============================] - 2s 19ms/step - loss: 0.7106 - accuracy: 0.4712\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.6713 - accuracy: 0.5745\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.6262\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6851\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.7308\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6051 - accuracy: 0.7248\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.7608\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7560\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5255 - accuracy: 0.7692\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.5126 - accuracy: 0.7692\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.4997 - accuracy: 0.7752\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7800\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.4807 - accuracy: 0.7825\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4745 - accuracy: 0.7849\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.4685 - accuracy: 0.7885\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7909\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7933\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7957\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7981\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 1s 8ms/step - loss: 0.4484 - accuracy: 0.7993\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8017\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8041\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.8065\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.8053\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8089\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8101\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8101\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8113\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8101\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8101\n",
      "13/13 [==============================] - 1s 71ms/step\n",
      "Epoch 1/30\n",
      "52/52 [==============================] - 2s 20ms/step - loss: 0.7107 - accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 0.6728 - accuracy: 0.5048\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6504 - accuracy: 0.5913\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.6430\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.6354 - accuracy: 0.6887\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.7260\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5689 - accuracy: 0.7572\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7812\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5235 - accuracy: 0.7861\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5048 - accuracy: 0.7921\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7897\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7945\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.8005\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.8005\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.8005\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.8017\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.4401 - accuracy: 0.8029\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.8017\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8077\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8101\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.4221 - accuracy: 0.8125\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8137\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8209\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8209\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8245\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8209\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.3971 - accuracy: 0.8293\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4023 - accuracy: 0.8257\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.8281\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/30\n",
      "52/52 [==============================] - 3s 20ms/step - loss: 0.7223 - accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.5349\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.5901\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6562\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7079\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.7260\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.7344\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7440\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7656\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7728\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7728\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4971 - accuracy: 0.7800\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4874 - accuracy: 0.7825\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7837\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7909\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7933\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7933\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7957\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.4520 - accuracy: 0.7981\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4481 - accuracy: 0.7993\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.8017\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.8017\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8065\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8077\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.8065\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.4273 - accuracy: 0.8077\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 0.4268 - accuracy: 0.8077\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.4218 - accuracy: 0.8149\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8161\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8173\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "52/52 [==============================] - 1s 8ms/step - loss: 0.7166 - accuracy: 0.4964\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.5180\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.5998\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.6394\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.7043\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.7248\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.6016 - accuracy: 0.7380\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.5803 - accuracy: 0.7404\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7572\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7716\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7716\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7764\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7776\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.4925 - accuracy: 0.7825\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4860 - accuracy: 0.7837\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7873\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7909\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7933\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7945\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7945\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 0.4590 - accuracy: 0.7981\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 0.4553 - accuracy: 0.7993\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.8005\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.8017\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.8053\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.4436 - accuracy: 0.8065\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4399 - accuracy: 0.8077\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8089\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8101\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8101\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 1/30\n",
      "52/52 [==============================] - 3s 40ms/step - loss: 0.6969 - accuracy: 0.4531\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.6909 - accuracy: 0.5685\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.6538\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.6923\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7224\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.7392\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.5762 - accuracy: 0.7644\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7668\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7764\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7812\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7861\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7861\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.4758 - accuracy: 0.7921\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7921\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7945\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7945\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7945\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.8005\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.4475 - accuracy: 0.8017\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.4442 - accuracy: 0.8005\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4420 - accuracy: 0.8005\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8017\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.8017\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8041\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.8065\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8077\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4267 - accuracy: 0.8077\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 0.4246 - accuracy: 0.8077\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4224 - accuracy: 0.8077\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8077\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/30\n",
      "52/52 [==============================] - 2s 19ms/step - loss: 0.7280 - accuracy: 0.3690\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.5889\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.6526\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.7139\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.7163\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7356\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5584 - accuracy: 0.7548\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7632\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7656\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5088 - accuracy: 0.7680\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7704\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4897 - accuracy: 0.7752\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.4827 - accuracy: 0.7788\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7825\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7837\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4674 - accuracy: 0.7825\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7861\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7873\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7909\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.4527 - accuracy: 0.7921\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.4498 - accuracy: 0.7945\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7969\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7981\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7993\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8041\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8053\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.4334 - accuracy: 0.8053\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4313 - accuracy: 0.8077\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8077\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8101\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Epoch 1/30\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.7016 - accuracy: 0.4303\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.6274\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6999 - accuracy: 0.4447\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.7151\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.6971\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6013 - accuracy: 0.7440\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.7536\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7704\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7776\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7776\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4917 - accuracy: 0.7837\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4800 - accuracy: 0.7909\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7921\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7921\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7981\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4497 - accuracy: 0.8029\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.4449 - accuracy: 0.8041\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.4399 - accuracy: 0.8065\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.8077\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.8113\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8125\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8125\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.4211 - accuracy: 0.8149\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4189 - accuracy: 0.8185\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8209\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8221\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8233\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8233\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8245\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.4009 - accuracy: 0.8281\n",
      "13/13 [==============================] - 0s 24ms/step\n",
      "Epoch 1/30\n",
      "52/52 [==============================] - 2s 15ms/step - loss: 0.7111 - accuracy: 0.4688\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.5709\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.6238\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.6467 - accuracy: 0.6923\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6204 - accuracy: 0.7175\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7368\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.7464\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 0.5481 - accuracy: 0.7536\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.5316 - accuracy: 0.7584\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7656\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7764\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7764\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7825\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.4761 - accuracy: 0.7837\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4700 - accuracy: 0.7849\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4646 - accuracy: 0.7897\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7921\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7945\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7969\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7993\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8017\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4436 - accuracy: 0.8017\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4408 - accuracy: 0.8041\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8041\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8053\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.8065\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8077\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.4270 - accuracy: 0.8101\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 2s 37ms/step - loss: 0.4239 - accuracy: 0.8089\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.4209 - accuracy: 0.8125\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 2s 33ms/step - loss: 0.7103 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6786 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6726 - accuracy: 0.5288\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.5733\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6538\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.7188\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.7380\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.7716\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.7740\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7849\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 2s 9ms/step - loss: 0.6998 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.5276\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.5757\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6575\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6312 - accuracy: 0.7224\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.7536\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.7740\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7812\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7897\n",
      "7/7 [==============================] - 0s 73ms/step\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 3s 59ms/step - loss: 0.7093 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6795 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6659 - accuracy: 0.5300\n",
      "Epoch 4/10\n",
      "17/26 [==================>...........] - ETA: 0s - loss: 0.5991 - accuracy: 0.7812"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-53b8572e2333>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run model for different lags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# returns tuple of the lag and the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mneural_network_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{lag}_month_lag_results\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_network_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-74-53b8572e2333>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run model for different lags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# returns tuple of the lag and the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mneural_network_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{lag}_month_lag_results\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_network_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-a1109fa5e212>\u001b[0m in \u001b[0;36mneural_network_grid_search\u001b[0;34m(data, lag, test_size, scoring, param_grid)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# perform grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mgrid_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# get best model from the grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1489\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         self._fit(\n\u001b[0m\u001b[1;32m    761\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_model_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m         self._fit_keras_model(\n\u001b[0m\u001b[1;32m    929\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"history_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1796\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[1;32m   1800\u001b[0m                             \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m             \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1412\u001b[0m             can_run_full_execution = (\n\u001b[1;32m   1413\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    691\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run model for different lags\n",
    "# returns tuple of the lag and the results\n",
    "neural_network_results = [(f\"{lag}_month_lag_results\", neural_network_grid_search(data_raw, lag, 0.2, 'f1', param_grid)) for lag in lags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmuUUT4dOTFr"
   },
   "outputs": [],
   "source": [
    "# make a dataframe of all accuracy results\n",
    "headers_metrics = ['lag', 'accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'threshold', 'conf_matrix']\n",
    "# store the results for each iteration\n",
    "iteration_metrics = []\n",
    "# iterate over results\n",
    "for result in neural_network_results:\n",
    "    # extract from the tuple\n",
    "    metrics = result[1]['model_metrics']\n",
    "    # extract each value\n",
    "    values = [val for _, val in metrics.items()]\n",
    "    # insert name of lag\n",
    "    values.insert(0, result[0])\n",
    "    # get the best threshold value for each lag\n",
    "    threshold = result[1]['best_threshold']\n",
    "    # append to values\n",
    "    values.append(threshold)\n",
    "    # get the confusion matric\n",
    "    conf_matrix = result[1]['confusion_matrix']\n",
    "    # append to values\n",
    "    values.append(conf_matrix)\n",
    "    # append to the list\n",
    "    iteration_metrics.append(values)\n",
    "# convert to a dataframe\n",
    "metric_data = pd.DataFrame(iteration_metrics, columns=headers_metrics)\n",
    "\n",
    "print(metric_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pN358Y57ImLc"
   },
   "outputs": [],
   "source": [
    "# go through and see if the model is over or underestimating recessions\n",
    "headers_false_true_summary = ['lag', 'recession_true', 'recession_true_pred', 'recession_false', 'recession_false_pred', 'false_pos_rate', 'false_neg_rate']\n",
    "\n",
    "# store iteration calculations\n",
    "iteration_summaries = []\n",
    "\n",
    "# loop over data\n",
    "for result in neural_network_results:\n",
    "    # extract the relevant data\n",
    "    data = result[1]\n",
    "    y_true_pred = pd.DataFrame({'y_actual': data['y_true'], 'y_predicted': data['predicted_vals_binary']})\n",
    "\n",
    "    # create row of data with the calculations\n",
    "    true_pos = np.sum(y_true_pred['y_actual'] == 1)\n",
    "    true_neg = np.sum(y_true_pred['y_actual'] == 0)\n",
    "    pred_pos = np.sum(y_true_pred['y_predicted'] == 1)\n",
    "    false_pos_rate = np.sum((y_true_pred['y_actual'] == 0) & (y_true_pred['y_predicted'] == 1)) / (np.sum(y_true_pred['y_actual'] == 0))\n",
    "    false_neg_rate = np.sum((y_true_pred['y_actual'] == 1) & (y_true_pred['y_predicted'] == 0)) / (np.sum(y_true_pred['y_actual'] == 1))\n",
    "\n",
    "    # create a list of the stats to pass in\n",
    "    summary_stats = [true_pos, pred_pos, true_neg, len(y_true_pred) - pred_pos, false_pos_rate, false_neg_rate]\n",
    "\n",
    "    # insert lag name\n",
    "    summary_stats.insert(0, result[0])\n",
    "\n",
    "    # append to result list\n",
    "    iteration_summaries.append(summary_stats)\n",
    "\n",
    "# convert to df\n",
    "complete_summary_stats = pd.DataFrame(iteration_summaries, columns=headers_false_true_summary)\n",
    "\n",
    "# print results\n",
    "print(complete_summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TO8KQg4VxDoR"
   },
   "outputs": [],
   "source": [
    "# write data to excel to transfer to local file\n",
    "# we will do further data processing in another script\n",
    "path = '/content/nn-results.xlsx'\n",
    "writer = pd.ExcelWriter(path, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVPZNAYDSEpF"
   },
   "outputs": [],
   "source": [
    "# add the metric summary to the excel file\n",
    "metric_data.to_excel(writer, sheet_name='summary_stats', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKHlekWSy69J"
   },
   "outputs": [],
   "source": [
    "# loop over the results and export the metrics\n",
    "for result_data in neural_network_results:\n",
    "    # extract the relevant data\n",
    "    sheet_name_start = result_data[0]\n",
    "    data = result_data[1]\n",
    "    # create sheet of results that represents actual and predicted vals\n",
    "    actual_and_predicted = pd.DataFrame({'y_actual': data['y_true'], 'y_predicted': data['predicted_vals_binary']})\n",
    "    # add data to new sheet\n",
    "    actual_and_predicted.to_excel(writer, sheet_name=sheet_name_start + '_act_pred', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3m9OEmi2OXCe"
   },
   "outputs": [],
   "source": [
    "# add summary stats to excel output\n",
    "complete_summary_stats.to_excel(writer, sheet_name='pos_neg_acc_summary', index=False)\n",
    "# close writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRhSgh3G-rOB"
   },
   "outputs": [],
   "source": [
    "# write the models to another directory we an export\n",
    "models_dir = '/content/nn-models/'\n",
    "# create directory if doesn't exist\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "# loop over the models and extract each of them\n",
    "for lag, model_data in zip(lags, neural_network_results):\n",
    "    # write the model to binary and export it using pickle\n",
    "    with open(os.path.join(models_dir, f\"nn-model-{lag}-month-lag.pkl\"), \"wb\") as f:\n",
    "        # select the model and export\n",
    "        pickle.dump(model_data[1]['best_model'], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njHAruY7CRNx"
   },
   "outputs": [],
   "source": [
    "# create zip files of the folders we want to download\n",
    "!zip -r /content/nn-models.zip /content/nn-models\n",
    "!zip -r /content/nn-roc-plots.zip /content/nn-roc-plots\n",
    "!zip -r /content/nn-shap-plots.zip /content/nn-shap-plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJvyv8Z7DEkF"
   },
   "outputs": [],
   "source": [
    "# import files module to programatically donwload files\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MRb9-DsXDKoM"
   },
   "outputs": [],
   "source": [
    "# create list of zip folders to download\n",
    "download_zips = ['nn-models.zip', 'nn-roc-plots.zip', 'nn-shap-plots.zip']\n",
    "# loop and download\n",
    "for zip_folder in download_zips:\n",
    "  # use files module to download\n",
    "  files.download(zip_folder)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
